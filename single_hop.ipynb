{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1a13cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import random\n",
    "from typing import cast\n",
    "from datasets import load_dataset, Dataset\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "import torch\n",
    "import string\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3bbaa65-8b00-402b-b599-270b2738c779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load or set environment variables\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21278a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Config (tweak these)\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "K_RETRIEVE = 5\n",
    "N_EVAL = 5\n",
    "SENTENCE_TRANSFORMER_MODEL = \"all-mpnet-base-v2\"\n",
    "CHAT_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "\n",
    "# Check for GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f36bfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HotpotQA...\n",
      "Train size: 90447\n",
      "Validation size: 7405\n"
     ]
    }
   ],
   "source": [
    "# Load HotpotQA: use TRAIN for corpus, VALIDATION for evaluation\n",
    "print(\"Loading HotpotQA...\")\n",
    "ds_train = cast(Dataset, load_dataset(\"hotpot_qa\", \"distractor\", split=\"train\", streaming=False)) # cast to Dataset to avoid pylance error\n",
    "ds_val = cast(Dataset, load_dataset(\"hotpot_qa\", \"distractor\", split=\"validation\", streaming=False))\n",
    "\n",
    "print(\"Train size:\", len(ds_train))\n",
    "print(\"Validation size:\", len(ds_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba631161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraphs: 899667\n"
     ]
    }
   ],
   "source": [
    "# Build a corpus from TRAIN context only\n",
    "corpus_rows = []\n",
    "for example in ds_train:\n",
    "    titles = example[\"context\"][\"title\"]\n",
    "    sentences_lists = example[\"context\"][\"sentences\"]\n",
    "    for title, sents in zip(titles, sentences_lists):\n",
    "        paragraph_text = \" \".join(sents)\n",
    "        corpus_rows.append({\"title\": title, \"text\": paragraph_text})\n",
    "\n",
    "print(\"Paragraphs:\", len(corpus_rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43cf66fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks indexed: 979285\n"
     ]
    }
   ],
   "source": [
    "# Chunk with RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    ")\n",
    "\n",
    "texts, metas = [], []\n",
    "for r in corpus_rows:\n",
    "    chunks = text_splitter.split_text(r['text'])\n",
    "    texts.extend(chunks)\n",
    "    metas.extend([{\"title\": r['title']} for _ in chunks])\n",
    "\n",
    "print(\"Chunks indexed:\", len(texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2740b359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c5eb5432024ae49bb86651d920a2ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/30603 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build FAISS vector store with \n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=SENTENCE_TRANSFORMER_MODEL, \n",
    "    model_kwargs={\"device\": device}, # Use GPU if available\n",
    "    encode_kwargs={\"normalize_embeddings\": True}, \n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "vector_store = FAISS.from_texts(\n",
    "    texts,\n",
    "    embedding_model, \n",
    "    metadatas=metas\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e75c5713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d7f24bff0740a59c342f660a583061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Arthur magazine was a bi-monthly periodical that was founded in October 2002, by publisher Laris Kreslins and editor Jay Babcock.  It received favorable attention from other periodicals such as \"L.A. Weekly\", \"Print\", \"Punk Planet\" and \"Rolling Stone\".  \"Arthur\" featured photography and artwork from Spike Jonze, Art Spiegelman, Susannah Breslin, Gary Panter and Godspeed You!  Black Emperor.  Arthur's regular columnists included Byron Coley, Thurston Moore, Daniel Pinchbeck, Paul Cullum, Douglas Rushkoff, and T-Model Ford.\n",
      "Metadata: {'title': 'Arthur (magazine)'}\n",
      "\n",
      "Document 2:\n",
      "Arthur's Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century.  Edited by T.S. Arthur, it featured work by Edgar A. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G. Spear, and others.  In May 1846 it was merged into \"Godey's Lady's Book\".\n",
      "Metadata: {'title': \"Arthur's Magazine\"}\n",
      "\n",
      "Document 3:\n",
      "Arthur's Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century.  Edited by T.S. Arthur, it featured work by Edgar A. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G. Spear, and others.  In May 1846 it was merged into \"Godey's Lady's Book\".\n",
      "Metadata: {'title': \"Arthur's Magazine\"}\n",
      "\n",
      "Document 4:\n",
      "Arthur's Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century.  Edited by T.S. Arthur, it featured work by Edgar A. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G. Spear, and others.  In May 1846 it was merged into \"Godey's Lady's Book\".\n",
      "Metadata: {'title': \"Arthur's Magazine\"}\n",
      "\n",
      "Document 5:\n",
      "Arthur's Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century.  Edited by T.S. Arthur, it featured work by Edgar A. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G. Spear, and others.  In May 1846 it was merged into \"Godey's Lady's Book\".\n",
      "Metadata: {'title': \"Arthur's Magazine\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's test retrieval on 1 example\n",
    "query = \"Which magazine was started first Arthur's Magazine or First for Women?\"\n",
    "docs = vector_store.similarity_search(query, k=5)\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(doc.page_content)\n",
    "    print(\"Metadata:\", doc.metadata)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc3e933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer with LLM + Retrieved Docs\n",
    "llm = ChatOpenAI(model=CHAT_MODEL, temperature=0)\n",
    "\n",
    "SYSTEM_PROMPT = (\"You are a precise QA assistant. Return just the short answer phrase (no explanation).\")\n",
    "\n",
    "def build_user_prompt(question, passages):\n",
    "    bundle = \"\\n\\n\".join([f\"PASSAGE {i+1}:\\n{p}\" for i, p in enumerate(passages)])\n",
    "    return f\"{bundle}\\n\\nQUESTION: {question}\\nANSWER:\"\n",
    "\n",
    "def singlehop_answer(question, k = K_RETRIEVE):\n",
    "    docs = vector_store.similarity_search(question, k=k)\n",
    "    # Keep only the page content to reduce tokens\n",
    "    passages = [d.page_content for d in docs]\n",
    "    user_prompt = build_user_prompt(question, passages)\n",
    "    resp = llm.invoke([{\"role\":\"system\",\"content\": SYSTEM_PROMPT},\n",
    "                       {\"role\":\"user\",\"content\": user_prompt}])\n",
    "    pred = resp.content\n",
    "    return pred, passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46af9100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EM/F1 evaluation\n",
    "_ARTICLES = {\"a\", \"an\", \"the\"}\n",
    "_PUNCT = set(string.punctuation)\n",
    "\n",
    "def _normalize(s: str) -> str:\n",
    "    s = s.lower().strip()\n",
    "    # remove punctuation\n",
    "    s = \"\".join(ch for ch in s if ch not in _PUNCT)\n",
    "    # remove articles\n",
    "    tokens = [t for t in s.split() if t not in _ARTICLES]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def exact_match(pred: str, gold: str) -> float:\n",
    "    return 1.0 if _normalize(pred) == _normalize(gold) else 0.0\n",
    "\n",
    "def f1_score(pred: str, gold: str) -> float:\n",
    "    pred_tokens = _normalize(pred).split()\n",
    "    gold_tokens = _normalize(gold).split()\n",
    "    if len(pred_tokens) == 0 and len(gold_tokens) == 0:\n",
    "        return 1.0\n",
    "    if len(pred_tokens) == 0 or len(gold_tokens) == 0:\n",
    "        return 0.0\n",
    "    common = {}\n",
    "    for t in gold_tokens:\n",
    "        common[t] = common.get(t, 0) + 1\n",
    "    num_same = 0\n",
    "    for t in pred_tokens:\n",
    "        if common.get(t, 0) > 0:\n",
    "            num_same += 1\n",
    "            common[t] -= 1\n",
    "    if num_same == 0:\n",
    "        return 0.0\n",
    "    precision = num_same / len(pred_tokens)\n",
    "    recall = num_same / len(gold_tokens)\n",
    "    return 2 * precision * recall / (precision + recall + 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde64dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c329d8558ef412993ef13d4ebc3037e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Were Scott Derrickson and Ed Wood of the same nationality?\n",
      "Pred: No.\n",
      "Gold: yes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12035dfa03ec46349e69e3de237f1774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c181e40deb11468d9913d944f3b60d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?\n",
      "Pred: None\n",
      "Gold: Chief of Protocol\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616e27b4675f4555b1fb6bbc5a3b8661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994266aa3e6d4639a79c40cc484f086e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What science fantasy young adult series, told in first person, has a set of companion books narrating the stories of enslaved worlds and alien species?\n",
      "Pred: The Wess'har Wars\n",
      "Gold: Animorphs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a55d54c3a5d4f03933ab2a89f934cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e56723def24d5ebc3bd30d885f2ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Are the Laleli Mosque and Esma Sultan Mansion located in the same neighborhood?\n",
      "Pred: No.\n",
      "Gold: no\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed48ea602221447da73a544f74614736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d563f52a4c44fc9ef0e589558ef9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: The director of the romantic comedy \"Big Stone Gap\" is based in what New York city?\n",
      "Pred: Not specified.\n",
      "Gold: Greenwich Village, New York City\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff34bc7c93b44efb8bbe31d6803fdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: {'n': 5, 'k': 5, 'EM': 0.2, 'F1': 0.19999999999989998, 'hit@k_any': 0.0, 'hit@k_all': 0.0}\n"
     ]
    }
   ],
   "source": [
    "def eval(ds, n, k=K_RETRIEVE):\n",
    "    # idxs = list(range(min(n, len(ds)))) # first n examples\n",
    "    idxs = random.sample(range(len(ds)), min(n, len(ds)))  # random n examples\n",
    "\n",
    "    ems, f1s = [], []\n",
    "\n",
    "    for i in idxs:\n",
    "        ex = ds[i]\n",
    "        q = ex[\"question\"]\n",
    "        gold_answer = ex[\"answer\"]\n",
    "\n",
    "        # Predictions from your singlehop system\n",
    "        pred, _ = singlehop_answer(q, k=k)\n",
    "        print(f\"Q: {q}\")\n",
    "        print(f\"Pred: {pred}\")\n",
    "        print(f\"Gold: {gold_answer}\")\n",
    "\n",
    "        ems.append(exact_match(pred, gold_answer))\n",
    "        f1s.append(f1_score(pred, gold_answer))\n",
    "\n",
    "    m = len(idxs) if idxs else 1\n",
    "    return {\n",
    "        \"n\": len(idxs),\n",
    "        \"k\": k,\n",
    "        \"EM\": sum(ems)/m,\n",
    "        \"F1\": sum(f1s)/m,\n",
    "    }\n",
    "\n",
    "# Run eval\n",
    "metrics = eval(ds_val, N_EVAL, k=K_RETRIEVE)\n",
    "print(\"Metrics:\", metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
