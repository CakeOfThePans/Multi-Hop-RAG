{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d1a13cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "from typing import cast\n",
    "from datasets import load_dataset, Dataset\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "import torch\n",
    "import string\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3bbaa65-8b00-402b-b599-270b2738c779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load or set environment variables\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21278a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Config (tweak these)\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "K_RETRIEVE = 5\n",
    "EMBEDDING_MODEL = \"BAAI/bge-large-en-v1.5\"\n",
    "CHAT_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "# Check for GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f36bfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HotpotQA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9765ec8f13fd4f61b7c806f14a516393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fullwiki/train-00000-of-00002.parquet:   0%|          | 0.00/166M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f8c39efdc34befbc8e4cbacc7a05a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fullwiki/train-00001-of-00002.parquet:   0%|          | 0.00/166M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0418be7b9042218730bf5ded96d22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fullwiki/validation-00000-of-00001.parqu(…):   0%|          | 0.00/28.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c64b3ec1094f6fa7151aabde95643c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fullwiki/test-00000-of-00001.parquet:   0%|          | 0.00/27.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75634ea3be6d42c688d188b9c91958e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/90447 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3129a4be2c44b61a6838cad71f336dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/7405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0592228c7b59482e909c4696b63e68e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 90447\n",
      "Validation size: 7405\n"
     ]
    }
   ],
   "source": [
    "# Load HotpotQA: use TRAIN for corpus, VALIDATION for evaluation\n",
    "print(\"Loading HotpotQA...\")\n",
    "ds_train = cast(Dataset, load_dataset(\"hotpot_qa\", \"fullwiki\", split=\"train\", streaming=False)) # cast to Dataset to avoid pylance error\n",
    "ds_val = cast(Dataset, load_dataset(\"hotpot_qa\", \"fullwiki\", split=\"validation\", streaming=False))\n",
    "\n",
    "print(\"Train size:\", len(ds_train))\n",
    "print(\"Validation size:\", len(ds_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba631161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraphs: 508826\n"
     ]
    }
   ],
   "source": [
    "# Build a corpus\n",
    "corpus_rows = []\n",
    "for example in ds_train:\n",
    "    titles = example[\"context\"][\"title\"]\n",
    "    sentences_lists = example[\"context\"][\"sentences\"]\n",
    "    for title, sents in zip(titles, sentences_lists):\n",
    "        paragraph_text = \" \".join(sents)\n",
    "        corpus_rows.append({\"title\": title, \"text\": paragraph_text})\n",
    "\n",
    "# Remove duplicates\n",
    "unique_seen = set()\n",
    "unique_rows = []\n",
    "for row in corpus_rows:\n",
    "    clean_text = re.sub(r\"\\s+\", \" \", row[\"text\"]).strip().lower()\n",
    "    key = (row[\"title\"], clean_text)\n",
    "    if key not in unique_seen:\n",
    "        unique_seen.add(key)\n",
    "        unique_rows.append({\"title\": row[\"title\"], \"text\": row[\"text\"]})\n",
    "\n",
    "corpus_rows = unique_rows\n",
    "print(\"Paragraphs:\", len(corpus_rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43cf66fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks indexed: 505435\n"
     ]
    }
   ],
   "source": [
    "# Chunk with RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    ")\n",
    "\n",
    "texts, metas = [], []\n",
    "for r in corpus_rows:\n",
    "    chunks = text_splitter.split_text(r['text'])\n",
    "    texts.extend(chunks)\n",
    "    metas.extend([{\"title\": r['title']} for _ in chunks])\n",
    "\n",
    "print(\"Chunks indexed:\", len(texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2740b359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing FAISS vector store from faiss_hotpotqa...\n"
     ]
    }
   ],
   "source": [
    "# Build or load FAISS vector store (TODO: move this and the code b4 to a separate script to reuse later)\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL, \n",
    "    model_kwargs={\"device\": device}, # Use GPU if available\n",
    "    encode_kwargs={\"normalize_embeddings\": True}, \n",
    "    # show_progress=True\n",
    ")\n",
    "\n",
    "if os.path.exists(\"faiss_hotpotqa\"):\n",
    "    print(\"Loading existing FAISS vector store from faiss_hotpotqa...\")\n",
    "    vector_store = FAISS.load_local(\"faiss_hotpotqa\", embedding_model, allow_dangerous_deserialization=True)\n",
    "else:\n",
    "    print(\"Creating new FAISS vector store...\")\n",
    "    vector_store = FAISS.from_texts(\n",
    "        texts,\n",
    "        embedding_model, \n",
    "        metadatas=metas\n",
    "    )\n",
    "\n",
    "    # Save vector store to disk for future use\n",
    "    vector_store.save_local(\"faiss_hotpotqa\")\n",
    "    print(\"FAISS vector store saved to faiss_hotpotqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer with LLM + Retrieved Docs\n",
    "llm = ChatOpenAI(model=CHAT_MODEL, temperature=0)\n",
    "\n",
    "SYSTEM_PROMPT = (\"You are a precise QA assistant. Return just the short answer phrase with no explanation, and no full sentences.\")\n",
    "\n",
    "def build_user_prompt(question, passages):\n",
    "    bundle = \"\\n\\n\".join([f\"PASSAGE {i+1}:\\n{p}\" for i, p in enumerate(passages)])\n",
    "    return f\"{bundle}\\n\\nQUESTION: {question}\\nANSWER:\"\n",
    "\n",
    "def singlehop_answer(question, k = K_RETRIEVE):\n",
    "    docs = vector_store.similarity_search(question, k=k)\n",
    "    # Keep only the page content to reduce tokens\n",
    "    passages = [d.page_content for d in docs]\n",
    "    user_prompt = build_user_prompt(question, passages)\n",
    "    resp = llm.invoke([{\"role\":\"system\",\"content\": SYSTEM_PROMPT},\n",
    "                       {\"role\":\"user\",\"content\": user_prompt}])\n",
    "    pred = resp.content\n",
    "    return pred, passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8f560bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: The director of the romantic comedy \"Big Stone Gap\" is based in what New York city?\n",
      "Predicted Answer: Not applicable.\n",
      "Retrieved Passages:\n",
      "Passage 1:\n",
      "Big Stone Gap is a 2014 American drama romantic comedy film written and directed by Adriana Trigiani and produced by Donna Gigliotti for Altar Identity Studios, a subsidiary of Media Society.  Based on Trigiani's 2000 best-selling novel of the same name, the story is set in the actual Virginia town of Big Stone Gap circa 1970s.  The film had its world premiere at the Virginia Film Festival on November 6, 2014.\n",
      "\n",
      "Passage 2:\n",
      "Little Manhattan is a 2005 American romantic comedy film directed and written by husband and wife Mark Levin and Jennifer Flackett.  Though Levin is credited as the director and Flackett as the writer, in the film's DVD commentary the two reveal that they collaborated on both tasks.  \"Little Manhattan\" depicts the story of ten-year-old Gabe's realization that girls can be pretty and nice to be with.  The story takes place, and was filmed on location, in Manhattan, mostly in the Upper West Side.  The film stars Josh Hutcherson and Charlie Ray in the leading roles of the two children.  It was Ray's first film role having never previously attended an audition.  The character of Rosemary at the kindergarten stage, seen in a flashback, was played by the writer-director team's real-life daughter.\n",
      "\n",
      "Passage 3:\n",
      "Judd Apatow ( ; born December 6, 1967) is an American comedian and film/television producer, writer, director and actor.  He is the founder of Apatow Productions, through which he produced and developed the television series \"Freaks and Geeks\", \"Undeclared\", \"Girls, Love\" and \"Crashing\" and directed the films \"The 40-Year-Old Virgin\" (2005), \"Knocked Up\" (2007), \"Funny People\" (2009), \"This Is 40\" (2012), and \"Trainwreck\" (2015).\n",
      "\n",
      "Passage 4:\n",
      "The Big Sick is a 2017 American romantic comedy film directed by Michael Showalter and written by Emily V. Gordon and Kumail Nanjiani.  It stars Nanjiani, Zoe Kazan, Holly Hunter, Ray Romano, Adeel Akhtar, and Anupam Kher, and follows an interracial couple that has to deal with their cultural differences, loosely based on the real-life romance between Nanjiani and Gordon.\n",
      "\n",
      "Passage 5:\n",
      "William Oliver Stone (born September 15, 1946) is an American screenwriter, film producer, and director of motion pictures and documentaries.  Stone won an Academy Award for Best Adapted Screenplay as writer of \"Midnight Express\" (1978).  He also wrote the acclaimed gangster movie \"Scarface\" (1983).  As a director, Stone achieved prominence as director/writer of the war drama \"Platoon\" (1986), for which Stone won the Academy Award for Best Director; the film was awarded Best Picture.  \"Platoon\" was the first in a trilogy of films based on the Vietnam War, in which Stone served as an infantry soldier.  He continued the series with \"Born on the Fourth of July\" (1989)—for which Stone won his second Best Director Oscar—and \"Heaven & Earth\" (1993).  Stone's other notable works include the Salvadoran Civil War-based drama \"Salvador\" (1986); the financial drama \"Wall Street\" (1987) and its 2010 sequel \"\"; the Jim Morrison biopic \"The Doors\" (1991); and a trilogy of films based on the American\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's test on one example\n",
    "query = \"The director of the romantic comedy \\\"Big Stone Gap\\\" is based in what New York city?\"\n",
    "pred, passages = singlehop_answer(query, k=K_RETRIEVE)\n",
    "print(\"Question:\", query)\n",
    "print(\"Predicted Answer:\", pred)\n",
    "print(\"Retrieved Passages:\")\n",
    "for i, p in enumerate(passages):\n",
    "    print(f\"Passage {i+1}:\\n{p}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46af9100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EM/F1 evaluation\n",
    "def normalize_answer(s):\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    normalized_prediction = normalize_answer(prediction)\n",
    "    normalized_ground_truth = normalize_answer(ground_truth)\n",
    "\n",
    "    if normalized_prediction in ['yes', 'no'] and normalized_prediction != normalized_ground_truth:\n",
    "        return 0\n",
    "    if normalized_ground_truth in ['yes', 'no'] and normalized_prediction != normalized_ground_truth:\n",
    "        return 0\n",
    "\n",
    "    prediction_tokens = normalized_prediction.split()\n",
    "    ground_truth_tokens = normalized_ground_truth.split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return 1.0 if (normalize_answer(prediction) == normalize_answer(ground_truth)) else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fde64dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Were Scott Derrickson and Ed Wood of the same nationality?\n",
      "Pred: Yes.\n",
      "Ground Truth: yes\n",
      "Q: What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?\n",
      "Pred: None\n",
      "Ground Truth: Chief of Protocol\n",
      "Q: What science fantasy young adult series, told in first person, has a set of companion books narrating the stories of enslaved worlds and alien species?\n",
      "Pred: Animorphs\n",
      "Ground Truth: Animorphs\n",
      "Q: Are the Laleli Mosque and Esma Sultan Mansion located in the same neighborhood?\n",
      "Pred: No.\n",
      "Ground Truth: no\n",
      "Q: The director of the romantic comedy \"Big Stone Gap\" is based in what New York city?\n",
      "Pred: Not applicable\n",
      "Ground Truth: Greenwich Village, New York City\n",
      "Q: 2014 S/S is the debut album of a South Korean boy group that was formed by who?\n",
      "Pred: YG Entertainment\n",
      "Ground Truth: YG Entertainment\n",
      "Q: Who was known by his stage name Aladin and helped organizations improve their performance as a consultant?\n",
      "Pred: Eenasul Fateh\n",
      "Ground Truth: Eenasul Fateh\n",
      "Q: The arena where the Lewiston Maineiacs played their home games can seat how many people?\n",
      "Pred: The Androscoggin Bank Colisée capacity is not specified in the passages.\n",
      "Ground Truth: 3,677 seated\n",
      "Q: Who is older, Annie Morton or Terry Richardson?\n",
      "Pred: Terry Richardson\n",
      "Ground Truth: Terry Richardson\n",
      "Q: Are Local H and For Against both from the United States?\n",
      "Pred: Yes.\n",
      "Ground Truth: yes\n",
      "Q: What is the name of the fight song of the university whose main campus is in Lawrence, Kansas and whose branch campuses are in the Kansas City metropolitan area?\n",
      "Pred: The university does not have a fight song mentioned in the passages.\n",
      "Ground Truth: Kansas Song\n",
      "Q: What screenwriter with credits for \"Evolution\" co-wrote a film starring Nicolas Cage and Téa Leoni?\n",
      "Pred: David Diamond\n",
      "Ground Truth: David Weissman\n",
      "Q: What year did Guns N Roses perform a promo for a movie starring Arnold Schwarzenegger as a former New York Police detective?\n",
      "Pred: 1991\n",
      "Ground Truth: 1999\n",
      "Q: Are Random House Tower and 888 7th Avenue both used for real estate?\n",
      "Pred: Yes.\n",
      "Ground Truth: no\n",
      "Q: The football manager who recruited David Beckham managed Manchester United during what timeframe?\n",
      "Pred: 1986 to 2013\n",
      "Ground Truth: from 1986 to 2013\n",
      "Q: Brown State Fishing Lake is in a country that has a population of how many inhabitants ?\n",
      "Pred: United States\n",
      "Ground Truth: 9,984\n",
      "Q: The Vermont Catamounts men's soccer team currently competes in a conference that was formerly known as what from 1988 to 1996?\n",
      "Pred: North Atlantic Conference\n",
      "Ground Truth: the North Atlantic Conference\n",
      "Q: Are Giuseppe Verdi and Ambroise Thomas both Opera composers ?\n",
      "Pred: Yes.\n",
      "Ground Truth: yes\n",
      "Q: Roger O. Egeberg was Assistant Secretary for Health and Scientific Affairs during the administration of a president that served during what years?\n",
      "Pred: 1969-1974\n",
      "Ground Truth: 1969 until 1974\n",
      "Q: Which writer was from England, Henry Roth or Robert Erskine Childers?\n",
      "Pred: Robert Erskine Childers\n",
      "Ground Truth: Robert Erskine Childers DSC\n",
      "Q: Which other Mexican Formula One race car driver has held the podium besides the Force India driver born in 1990?\n",
      "Pred: Esteban Gutiérrez\n",
      "Ground Truth: Pedro Rodríguez\n",
      "Q: This singer of A Rather Blustery Day also voiced what hedgehog?\n",
      "Pred: Bunnie Rabbot\n",
      "Ground Truth: Sonic\n",
      "Q: Aside from the Apple Remote, what other device can control the program Apple Remote was originally designed to interact with?\n",
      "Pred: Siri Remote\n",
      "Ground Truth: keyboard function keys\n",
      "Q: Which performance act has a higher instrument to person ratio, Badly Drawn Boy or Wolf Alice? \n",
      "Pred: Badly Drawn Boy\n",
      "Ground Truth: Badly Drawn Boy\n",
      "Q: What was the father of Kasper Schmeichel voted to be by the IFFHS in 1992?\n",
      "Pred: World's Best Goalkeeper\n",
      "Ground Truth: World's Best Goalkeeper\n",
      "Q: Who was the writer of These Boots Are Made for Walkin' and who died in 2007?\n",
      "Pred: Lee Hazlewood\n",
      "Ground Truth: Barton Lee Hazlewood\n",
      "Q: The 2011–12 VCU Rams men's basketball team, led by third year head coach Shaka Smart, represented Virginia Commonwealth University which was founded in what year?\n",
      "Pred: 1968\n",
      "Ground Truth: 1838\n",
      "Q: Are both Dictyosperma, and Huernia described as a genus?\n",
      "Pred: Yes.\n",
      "Ground Truth: yes\n",
      "Q: Kaiser Ventures corporation was founded by an American industrialist who became known as the father of modern American shipbuilding?\n",
      "Pred: Yes.\n",
      "Ground Truth: Henry J. Kaiser\n",
      "Q: What is the name for the adventure in \"Tunnels and Trolls\", a game designed by Ken St. Andre?\n",
      "Pred: Tunnels & Trolls\n",
      "Ground Truth: Arena of Khazan\n",
      "Q: When was Poison's album \"Shut Up, Make Love\" released?\n",
      "Pred: \"Shut Up, Make Love\" is a song, not an album.\n",
      "Ground Truth: 2000\n",
      "Q: Hayden is a singer-songwriter from Canada, but where does Buck-Tick hail from?\n",
      "Pred: Japan\n",
      "Ground Truth: Fujioka, Gunma\n",
      "Q: Which  French ace pilot and adventurer fly L'Oiseau Blanc\n",
      "Pred: Charles Nungesser\n",
      "Ground Truth: Charles Eugène\n",
      "Q: Are Freakonomics and In the Realm of the Hackers both American documentaries?\n",
      "Pred: No.\n",
      "Ground Truth: no\n",
      "Q: Which band, Letters to Cleo or Screaming Trees, had more members?\n",
      "Pred: Screaming Trees\n",
      "Ground Truth: Letters to Cleo\n",
      "Q: Alexander Kerensky was defeated and destroyed by the Bolsheviks in the course of a civil war that ended when ?\n",
      "Pred: The Red control of the newly formed Soviet Union was assured in 1923.\n",
      "Ground Truth: October 1922\n",
      "Q: Seven Brief Lessons on Physics was written by an Italian physicist that has worked in France since what year?\n",
      "Pred: Not applicable.\n",
      "Ground Truth: 2000\n",
      "Q: The Livesey Hal War Memorial commemorates the fallen of which war, that had over 60 million casualties?\n",
      "Pred: World War II\n",
      "Ground Truth: World War II\n",
      "Q: Are both Elko Regional Airport and Gerald R. Ford International Airport located in Michigan?\n",
      "Pred: No.\n",
      "Ground Truth: no\n",
      "Q: Ralph Hefferline was a psychology professor at a university that is located in what city?\n",
      "Pred: New York City\n",
      "Ground Truth: New York City\n",
      "Q: Which dog's ancestors include Gordon and Irish Setters: the Manchester Terrier or the Scotch Collie?\n",
      "Pred: Scotch Collie\n",
      "Ground Truth: Scotch Collie\n",
      "Q: Where is the company that Sachin Warrier worked for as a software engineer headquartered? \n",
      "Pred: Kochi\n",
      "Ground Truth: Mumbai\n",
      "Q: A Japanese manga series based on a 16 year old high school student Ichitaka Seto, is written and illustrated by someone born in what year?\n",
      "Pred: 1966\n",
      "Ground Truth: 1962\n",
      "Q: The battle in which Giuseppe Arimondi lost his life secured what for Ethiopia?\n",
      "Pred: Ethiopian sovereignty.\n",
      "Ground Truth: sovereignty\n",
      "Q: Alfred Balk served as the secretary of the Committee on the Employment of Minority Groups in the News Media under which United States Vice President?\n",
      "Pred: Nelson Rockefeller\n",
      "Ground Truth: Nelson Rockefeller\n",
      "Q: A medieval fortress in Dirleton, East Lothian, Scotland borders on the south side of what coastal area?\n",
      "Pred: Yellowcraig\n",
      "Ground Truth: Yellowcraig\n",
      "Q: Who is the writer of this song that was inspired by words on a tombstone and was the first track on the box set Back to Mono?\n",
      "Pred: Phil Spector\n",
      "Ground Truth: Phil Spector\n",
      "Q: What type of forum did a former Soviet statesman initiate?\n",
      "Pred: Political forum\n",
      "Ground Truth: Organizations could come together to address global issues\n",
      "Q: Are Ferocactus and Silene both types of plant?\n",
      "Pred: Yes.\n",
      "Ground Truth: yes\n",
      "Q: Which British first-generation jet-powered medium bomber was used in the South West Pacific theatre of World War II?\n",
      "Pred: None\n",
      "Ground Truth: English Electric Canberra\n",
      "Q: Which year and which conference was the 14th season for this conference as part of the NCAA Division that the Colorado Buffaloes played in with a record of 2-6 in conference play?\n",
      "Pred: 2014, Pac-12 Conference\n",
      "Ground Truth: 2009 Big 12 Conference\n",
      "Q: In 1991 Euromarché was bought by a chain that operated how any hypermarkets at the end of 2016?\n",
      "Pred: 1,462 hypermarkets\n",
      "Ground Truth: 1,462\n",
      "Q: What race track in the midwest hosts a 500 mile race eavery May?\n",
      "Pred: Indianapolis Motor Speedway\n",
      "Ground Truth: Indianapolis Motor Speedway\n",
      "Q: In what city did the \"Prince of tenors\" star in a film based on an opera by Giacomo Puccini?\n",
      "Pred: West Germany\n",
      "Ground Truth: Rome\n",
      "Q: Ellie Goulding worked with what other writers on her third studio album, Delirium?\n",
      "Pred: Max Martin, Savan Kotecha, Ilya Salmanzadeh\n",
      "Ground Truth: Max Martin, Savan Kotecha and Ilya Salmanzadeh\n",
      "Q: Which Australian city founded in 1838 contains a boarding school opened by a Prime Minister of Australia and named after a school in London of the same name.\n",
      "Pred: Adelaide\n",
      "Ground Truth: Marion, South Australia\n",
      "Q: D1NZ is a series based on what oversteering technique?\n",
      "Pred: Drifting\n",
      "Ground Truth: Drifting\n",
      "Q: who is younger Keith Bostic or Jerry Glanville ?\n",
      "Pred: Keith Bostic\n",
      "Ground Truth: Keith Bostic\n",
      "Q: According to the 2001 census, what was the population of the city in which Kirton End is located?\n",
      "Pred: 273\n",
      "Ground Truth: 35,124\n",
      "Q: Are both Cypress and Ajuga genera?\n",
      "Pred: No.\n",
      "Ground Truth: no\n",
      "Q: What distinction is held by the former NBA player who was a member of the Charlotte Hornets during their 1992-93 season and was head coach for the WNBA team Charlotte Sting?\n",
      "Pred: Shortest player in NBA history.\n",
      "Ground Truth: shortest player ever to play in the National Basketball Association\n",
      "Q: What is the name of the executive producer of the film that has a score composed by Jerry Goldsmith?\n",
      "Pred: Francis Ford Coppola\n",
      "Ground Truth: Ronald Shusett\n",
      "Q: Who was born earlier, Emma Bull or Virginia Woolf?\n",
      "Pred: Virginia Woolf\n",
      "Ground Truth: Adeline Virginia Woolf\n",
      "Q: What was the Roud Folk Song Index of the nursery rhyme inspiring What Are Little Girls Made Of?\n",
      "Pred: 821\n",
      "Ground Truth: 821\n",
      "Q: Scott Parkin has been a vocal critic of Exxonmobil and another corporation that has operations in how many countries ?\n",
      "Pred: More than 180 countries.\n",
      "Ground Truth: more than 70 countries\n",
      "Q: What WB supernatrual drama series was Jawbreaker star Rose Mcgowan best known for being in?\n",
      "Pred: Charmed\n",
      "Ground Truth: Charmed\n",
      "Q: Vince Phillips held a junior welterweight title by an organization recognized by what larger Hall of Fame?\n",
      "Pred: International Boxing Hall of Fame (IBHOF)\n",
      "Ground Truth: International Boxing Hall of Fame\n",
      "Q: What is the name of the singer who's song was released as the lead single from the album \"Confessions\", and that had popular song stuck behind for eight consecutive weeks?\n",
      "Pred: Usher\n",
      "Ground Truth: Usher\n",
      "Q: who is the younger brother of The episode guest stars of The Hard Easy \n",
      "Pred: Brian Doyle-Murray\n",
      "Ground Truth: Bill Murray\n",
      "Q: The 2017–18 Wigan Athletic F.C. season will be a year in which the team competes in the league cup known as what for sponsorship reasons?\n",
      "Pred: Carabao Cup\n",
      "Ground Truth: Carabao Cup\n",
      "Q: Which of Tara Strong major voice role in animated series is an American animated television series based on the DC Comics fictional superhero team, the \"Teen Titans\"?\n",
      "Pred: Teen Titans Go!\n",
      "Ground Truth: Teen Titans Go!\n",
      "Q: What is the inhabitant of the city where  122nd SS-Standarte was formed in2014\n",
      "Pred: Strasbourg\n",
      "Ground Truth: 276,170 inhabitants\n",
      "Q: What color clothing do people of the Netherlands wear during Oranjegekte or to celebrate the national holiday Koningsdag? \n",
      "Pred: Orange\n",
      "Ground Truth: orange\n",
      "Q: What was the name of the 1996 loose adaptation of William Shakespeare's \"Romeo & Juliet\" written by James Gunn?\n",
      "Pred: Tromeo and Juliet\n",
      "Ground Truth: Tromeo and Juliet\n",
      "Q: Robert Suettinger was the national intelligence officer under which former Governor of Arkansas?\n",
      "Pred: Bill Clinton\n",
      "Ground Truth: William Jefferson Clinton\n",
      "Q: What American professional Hawaiian surfer born 18 October 1992 won the Rip Curl Pro Portugal?\n",
      "Pred: John John Florence\n",
      "Ground Truth: John John Florence\n",
      "Q: What is the middle name of the actress who plays Bobbi Bacha in Suburban Madness?\n",
      "Pred: Bacha\n",
      "Ground Truth: Ann\n",
      "Q: Alvaro Mexia had a diplomatic mission with which tribe of indigenous people?\n",
      "Pred: Ais\n",
      "Ground Truth: Apalachees\n",
      "Q: What nationality were social anthropologists Alfred Gell and Edmund Leach?\n",
      "Pred: British\n",
      "Ground Truth: British\n",
      "Q: In which year was the King who made the 1925 Birthday Honours born?\n",
      "Pred: 1865\n",
      "Ground Truth: 1865\n",
      "Q: What is the county seat of the county where East Lempster, New Hampshire is located?\n",
      "Pred: Newport\n",
      "Ground Truth: Newport\n",
      "Q: The Album Against the Wind was the 11th Album of a Rock singer Robert C Seger born may 6 1945. What was the Rock singers stage name ?\n",
      "Pred: Bob Seger\n",
      "Ground Truth: Bob Seger\n",
      "Q: Rostker v. Goldberg held that the practice of what way of filling armed forces vacancies was consitutional?\n",
      "Pred: Draft registration for men only.\n",
      "Ground Truth: Conscription\n",
      "Q: Handi-Snacks are a snack food product line sold by what American multinational confectionery, food, and beverage company that is based in Illinois?\n",
      "Pred: Mondelez International\n",
      "Ground Truth: Mondelez International, Inc.\n",
      "Q: What was the name of a woman from the book titled \"Their Lives: The Women Targeted by the Clinton Machine \" and was also a former white house intern?\n",
      "Pred: Monica Lewinsky\n",
      "Ground Truth: Monica Lewinsky\n",
      "Q: When was the American lawyer, lobbyist and political consultant who was a senior member of the presidential campaign of Donald Trump born?\n",
      "Pred: April 1, 1949\n",
      "Ground Truth: April 1, 1949\n",
      "Q: In what year was the novel that Lourenço Mutarelli based \"Nina\" on based first published?\n",
      "Pred: Not mentioned.\n",
      "Ground Truth: 1866\n",
      "Q: Where are Teide National Park and Garajonay National Park located?\n",
      "Pred: Canary Islands, Spain\n",
      "Ground Truth: Canary Islands, Spain\n",
      "Q: How many copies of Roald Dahl's variation on a popular anecdote sold?\n",
      "Pred: More than 250 million copies.\n",
      "Ground Truth: 250 million\n",
      "Q: What occupation do Chris Menges and Aram Avakian share?\n",
      "Pred: Film director\n",
      "Ground Truth: director\n",
      "Q: Andrew Jaspan was the co-founder of what not-for-profit media outlet?\n",
      "Pred: The Conversation\n",
      "Ground Truth: The Conversation\n",
      "Q: Which American film director hosted the 18th Independent Spirit Awards in 2002?\n",
      "Pred: John Waters\n",
      "Ground Truth: John Waters\n",
      "Q: Where does the hotel and casino located in which Bill Cosby's third album was recorded?\n",
      "Pred: Flamingo Hotel in Las Vegas, Nevada\n",
      "Ground Truth: Las Vegas Strip in Paradise\n",
      "Q: Do the drinks Gibson and Zurracapote both contain gin?\n",
      "Pred: No.\n",
      "Ground Truth: no\n",
      "Q: In what month is the annual documentary film festival, that is presented by the fortnightly published British journal of literary essays, held? \n",
      "Pred: March\n",
      "Ground Truth: March and April\n",
      "Q: Tysons Galleria is located in what county?\n",
      "Pred: Fairfax County\n",
      "Ground Truth: Fairfax County\n",
      "Q: Bordan Tkachuk was the CEO of a company that provides what sort of products?\n",
      "Pred: Technology products\n",
      "Ground Truth: IT products and services\n",
      "Q: Which filmmaker was known for animation, Lev Yilmaz or Pamela B. Green?\n",
      "Pred: Levni Yilmaz\n",
      "Ground Truth: Levni Yilmaz\n",
      "Q: In which city is the ambassador of the Rabat-Salé-Kénitra administrative region to China based?\n",
      "Pred: Rabat\n",
      "Ground Truth: Beijing\n",
      "Q: Are Yingkou and Fuding the same level of city?\n",
      "Pred: No.\n",
      "Ground Truth: no\n",
      "Metrics: {'n': 100, 'k': 5, 'EM': 0.46, 'F1': 0.5894277389277389}\n"
     ]
    }
   ],
   "source": [
    "def eval(ds, n, k=K_RETRIEVE):\n",
    "    idxs = list(range(min(n, len(ds)))) # first n examples\n",
    "\n",
    "    ems, f1s = [], []\n",
    "\n",
    "    for i in idxs:\n",
    "        ex = ds[i]\n",
    "        q = ex[\"question\"]\n",
    "        ground_truth = ex[\"answer\"]\n",
    "\n",
    "        # Predictions from your singlehop system\n",
    "        pred, _ = singlehop_answer(q, k=k)\n",
    "        print(f\"Q: {q}\")\n",
    "        print(f\"Pred: {pred}\")\n",
    "        print(f\"Ground Truth: {ground_truth}\")\n",
    "\n",
    "        ems.append(exact_match_score(pred, ground_truth))\n",
    "        f1s.append(f1_score(pred, ground_truth))\n",
    "\n",
    "    m = len(idxs) if idxs else 1\n",
    "    return {\n",
    "        \"n\": len(idxs),\n",
    "        \"k\": k,\n",
    "        \"EM\": sum(ems)/m,\n",
    "        \"F1\": sum(f1s)/m,\n",
    "    }\n",
    "\n",
    "# Run eval\n",
    "metrics = eval(ds_val, 100, k=K_RETRIEVE) # TODO: change N to ds_val size for full eval later\n",
    "print(\"Metrics:\", metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
